# testOdev
## Решение тестового задания в O.dev
### Введение
Передо мной была поставлена задача классификации отзывов о проживании в отеле. Необходимо было определить на основе отзыва, яляется ли отзыв негативным, нейтральным или положительным.
В качество решение предложена методика вкллючающая в себя предварительную обработку данных с поиском пропущенных переменных, анализ данных, включая подсчет корелляций между признаками и целевой переменной.
Далее был произведен отбор признаков с помощью различных методов и далее были обучены модели для классификации. Последним этапом стала оценка полученных результатов и сравнение работы нескольких моделей.

### Предварительная обработка данных и первичный анализ данных
На этапе препроцессинга с помощью метода info() были изучен датасет, а именно типы признаков, наличие отсутсвующих значений. Датасет не содержит пропущенные значения, поэтому нет необходимости их заполнять. Далее мною были рассмотрена распределения данных по признакамю было получено, что люди путешествующие в одиночку чаще оставляли негативные или нейтральные отзывы, при этом пол человека оставляющего отзыв не влияет на эмоциональную окраску отзыва. По оценке удовлетворенности посеттителей распределения по типу путешествия и по типу бронирования отеля похожи.

Следующий этап это подсчет корреляции признаков между собой и кореляции признаков с целевой переменной для выявления линейных и нелинейных зависимостей (использовалась корелляция Спирмана, однако результаты расчета корелляции Спирмана практически полностью совпадают с корелляцией Пирсона). Зависиомсти между целевой переменной и каким либо из признаков обнаружено не было, так как оценка по  коэффициенту Пирсона  дала диапазон (-0.5;0.5). 

Последний этап это обработка категориальных прихнаков. Так как категорий оказалось немного их можно заэнкодить простейшим one hot encoder. 

### Отбор признаков
Для отбора признаков были предложены два варианта:один с использованием алгоритма RandomForest и PCA

#### Random Forest
Алгоритм Randomf Forest (RF) удобен для получения важности признаков, так как в его основе лежат решающие деревья. Используя важность признаков полученных от RF можно отобрать топ 8 важных признаков.
Алгоритм Случайного леса не стоит применять в случае большого количества признаков в датасете из-за долгого вычисления результатов. В данной задаче это можно было делать без особых проблем так как количество признаков в датасете небольшое и составляет 23.
#### Principal Component Analysis

Использование PCA не совсем применимо именно для задачи отбора признаков, так как PCA не выбирает признаки, вычисляет новые с помощью линейных преобразований. Однако этот алгоритм очень полезен для сокращения размерности.  Для расчета главных векторов (principal components) в PCA расчитываются собственные вектора и собственные значения матрицы ковариации данных. При этом собственные значения полученные от матрицы ковариации равны объясненной дисперсии соответсвующего главного вектор. Поэтому PCA позволяет оценить долю обьясненной дисперсии.
Так как при расчете главных компонент считается матрица ковариации необходимо предварительно выполнить нормализацию данных. Мною быд применен предварительно скэйлинг данных с помощью StandardScaler, далее посчитана суммарная обьясненная дисперсия, которая показала, что 8 наиважнейших компонент объясняют 70% суммарной объясненной дисперсии, что может повлиять на качество модели, в сравнении если бы прогноз строился например на 20 признаках, так как 20 признаков объясняют 99% объясненной дисперсии. Далее был сформирован датасет включающий 8 главных компонент в качестве новых признаков.

### Обучение моделей
Начальный датасет был поделен на обучающую выборку и тестовую выборку в соотнощении train/test 9:1. Было решено использовать XGBoost классификатор, который успешно показывает себя при решении различных задач. Для отбора гиперпараметров был использован RandomizedSearchCV на 5 фолдах, так как этот поиск работает быстро и приводит к оптимальному набору параметров. Был выбран лучший набор гиперпараметров и далее выполнено предсказание на тесте. Для оценки использован classification report и f1 метрика. Метрика F1 является гармоническим средним для precision и recall и дает реальное представление о качестве работы модели для разных классов. Где precision можно трактовать как долю верно предсказанных экземпляров класса среди всех предсказаний, а recall (также известный как чувствительность) — это доля правильно предсказанных точек класса по отношению к общему количеству точек класса в выборке.  Для данных полученных по весам деревьев : 0.93( класс 0 неудов/нейтрально) и 0.91 (класс 1 удовл.) 
              precision    recall  f1-score   support

           0       0.93      0.93      0.93      5868
           1       0.90      0.91      0.91      4523

    accuracy                           0.92     10391
   macro avg       0.92      0.92      0.92     10391
weighted avg       0.92      0.92      0.92     10391

 для данных по PCA : 0.9(0) и  0.86 (1)
 
               precision    recall  f1-score   support

           0       0.88      0.92      0.90      5868
           1       0.89      0.84      0.86      4523

    accuracy                           0.88     10391
   macro avg       0.88      0.88      0.88     10391
weighted avg       0.88      0.88      0.88     10391
  Для альтернативного решения использовал  кастомной классификатор  с выходной функцией активации sigmoid и BCELoss функцией потерь так же трешхолд выставил ровно 0.5 для деления по классам  : f1 : 0.93( класс 0 неудов/нейтрально) и 0.91 (класс 1 удовл.) 
  
                precision    recall  f1-score   support

           0       0.93      0.93      0.93      5868
           1       0.91      0.91      0.91      4523

    accuracy                           0.92     10391
   macro avg       0.92      0.92      0.92     10391
weighted avg       0.92      0.92      0.92     10391
  но чуть лучше precision в сравнении с XGBoost , и на данных для PCA F1 = 0.9 и  0.87 снова в целом чуть лучше чем при XGB.

                precision    recall  f1-score   support

           0       0.89      0.91      0.90      5868
           1       0.87      0.86      0.87      4523

    accuracy                           0.88     10391
   macro avg       0.88      0.88      0.88     10391
weighted avg       0.88      0.88      0.88     10391

### Обсуждение результатов
В целом выборка была сбалансированна поэтому задачу усложнять не пришлось однако результаты можно улучшить - расширить диапазон  гиперпараметров и для XGB и для нейросети (попробовать динамический лернинг рейт другие оптимизаторы и  поэксперементировать с количеством нейронов и слоев). Так же для качества можно попробовать искусственно расширить выборку - например использовать автоэнкодер добавить восстановленные данные в обучение и посмотреть результат на тех же тестовых данных.
5. Детально с этапами работы можно ознакомиться в ноутбуке -  комментарии прикреплены.
