# testOdev
### Решение тестового задания в O.dev

1. На этапе препроцессинга методом info() смотрю на проблмы датасета (тип признаков  и отсутсвующие значения (их нет)), далее смотрю на распределения признаков и их корреляции с целевой переменной.Так как категорий оказалось немного - можно заэнкодить простейшим one hot encode. Линейно зависиомсти между целевой переменной и как им либо признаком не было (оценка по  коэф. Пирсона  дала диапазон (-0.5;0.5)) -> Линейные модели тестировать необязательно
2. Feature Selection. Разделил на два варианта : в первом использовал RandomForest для получения важности признаков и по ним выбрал топ 8 признаков,  в данной задаче это можно было делать без особых проблем так как размерность датасета небольшая (23признака).Вариант два не совсем про Feature Selection а скорее про понижения раззмерности с PCA так этот метод меняет исходный датасет. БЫл применен предварительно скэйлинг данных -> посчитано суммарная обьясненная дисперсия для топ 8 компонент это оказалось в районе  70%, что может повлиять на качество модели в сравнении если бы прогноз строился например на 20 признаках.  -> далее формирование датасета на 8 компонентах.
3. Обучение.Поделил данные как  train/test 9:1. Решил использовать XGB классифайер . Для отбора параметров использовал RandomizedSearchCV на 5 фолдах , выбрал лучший набор и далее предсказание на тесте. Для оценки использован classification report - f1 метрика для данных полученных по весам деревьев : 0.93( класс 0 неудов/нейтрально) и 0.91 (класс 1 удовл.) ; для данных по PCA : 0.9(0) и  0.86 (1). Для альтернативного решения использовал  кастомной классификатор  с выходной функцией активации sigmoid и BCELoss функцией потерь так же трешхолд выставил ровно 0.5 для деления по классам  : f1 : 0.93( класс 0 неудов/нейтрально) и 0.91 (класс 1 удовл.) но чуть лучше precision в сравнении с XGB , и на данных для PCA F1 = 0.9 и  0.87 снова в целом чуть лучше чем при XGB
4. Обсуждение :  в целом выборка была сбалансированна поэтому задачу усложнять не пришлось однако результаты можно улучшить - расширить диапазон  гиперпараметров и для XGB и для нейросети(попробовать динамический лернинг рейт другие оптимизаторы и  поэксперементировать с количеством нейронов и слоев). Так же для качества можно попробовать искусственно расширить выборку - например использовать автоэнкодер добавить восстановленные данные в обучение и посмотреть результат на тех же тестовых данных.
5. Детально с этапами работы можно ознакомиться в ноутбуке -  комментарии прикреплены 
